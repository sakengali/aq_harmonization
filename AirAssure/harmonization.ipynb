{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables to modify\n",
    "n_sensors = 21\n",
    "time_header = \"timestamp\" #header of the timestamp column\n",
    "folder_name = 'level1_airassure_data'\n",
    "first_timestamp = \"2023-12-18 00:00:00\"\n",
    "last_timestamp = \"2023-12-31 23:00:00\" #--fill data if there are missing values between these timestamps\n",
    "parameters = [\"pm1\", \"pm2.5\", \"pm4\", \"pm10\", \"co2\", \"tvoc\"] #set the parameter you want to harmonize; \n",
    "#the parameter name should be exactly the same as in the headers in the csv files, written in a list, ex. [\"PM 2.5\", \"PM 1.0\", \"CO2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking the lengths of the sensor data:\n",
      "[1344, 1344, 1344, 1344, 1344, 1344, 1344, 1344, 1344, 1344, 1344, 1344, 1344, 1344, 1344, 1344, 1344, 1344, 1344, 1344, 1344]\n"
     ]
    }
   ],
   "source": [
    "#read data\n",
    "data = []\n",
    "data = [pd.read_csv(f'{folder_name}/A' + str(i+1) + '.csv') for i in range(n_sensors)]\n",
    "sensor_names = [f'A{i+1}' for i in range(n_sensors)]\n",
    "\n",
    "print(\"checking the lengths of the sensor data:\")\n",
    "u = [len(data[i].index) for i in range(n_sensors)]\n",
    "print(u)\n",
    "\n",
    "#---------------------------------------\n",
    "#convert the timestamps to datetime type\n",
    "for i in range(n_sensors):\n",
    "    data[i][time_header] = pd.to_datetime(data[i][time_header])\n",
    "\n",
    "#set the timestamps as index\n",
    "start = pd.to_datetime(first_timestamp)\n",
    "end = pd.to_datetime(last_timestamp)\n",
    "dates = pd.date_range(start=start, end=end, freq='15Min')\n",
    "\n",
    "#fill the missing values with nan\n",
    "data = [data[i].set_index(time_header).reindex(dates).reset_index() for i in range(n_sensors)]\n",
    "\n",
    "#multiply voc by 1000\n",
    "data = [data[i]['tvoc'] * 1000 for i in range(n_sensors)]\n",
    "\n",
    "#create a folder to save results of harmonization\n",
    "result_folder = 'harmonization_results'\n",
    "level2_folder = 'level2_data'\n",
    "if not os.path.isdir(result_folder):\n",
    "    os.makedirs(f'./{result_folder}/{level2_folder}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonize(parameter):\n",
    "\n",
    "    #finding the median values for each timestamp - 'parameter_data' is 2-dimensional arrays to store the values of the parameter for all sensors\n",
    "    parameter_data = [data[i][parameter].values for i in range(n_sensors)]\n",
    "\n",
    "    #cut off sensors with missing days to find the median in a simpler way\n",
    "    parameter_data = np.array([parameter_data[i] for i in range(n_sensors)])\n",
    "    median = np.nanmedian(parameter_data, axis=0)\n",
    "\n",
    "    #-------------------------------------------------\n",
    "    #for plotting\n",
    "    plt_columns = n_sensors//5+1\n",
    "    figure, axis = plt.subplots(5, plt_columns)\n",
    "\n",
    "    #for regression\n",
    "    def func(x, a, b):\n",
    "        return a*x + b\n",
    "\n",
    "    #to save calibration factors\n",
    "    calibration_factors = np.zeros(n_sensors)\n",
    "    #to save harmonized data\n",
    "    harmonized_data = np.zeros((n_sensors, len(median)))\n",
    "    r2_values = np.zeros(n_sensors)\n",
    "\n",
    "    x = median\n",
    "    print(f'calculating harmonization data for {parameter} ...')\n",
    "    for i in range(n_sensors):\n",
    "        #plot the sensors' data against the median (the values are centralized to zero)\n",
    "        axis[i//plt_columns, i%plt_columns].plot(median, data[i][parameter], 'o')\n",
    "        axis[i//plt_columns, i%plt_columns].set_title(f\"Sensor A{[i]}\")\n",
    "        axis[i//plt_columns, i%plt_columns].set_xlabel(\"median\")\n",
    "\n",
    "        #regression for slope\n",
    "        y = data[i][parameter].values\n",
    "        \n",
    "        #to omit values with nan\n",
    "        valid = ~ (np.isnan(x) | np.isnan(y))\n",
    "\n",
    "        #regression (the values are centralized to zero, by setting the intercept to zero)\n",
    "        popt, pcov = curve_fit(func, x[valid], y[valid], bounds=([-np.inf, -0.000001], [np.inf, 0.000001]))\n",
    "        calibration_factors[i] = round(1/popt[0], 2)\n",
    "\n",
    "        #r2 value\n",
    "        residuals = y[valid] - func(x[valid], *popt)\n",
    "        ss_res = np.sum(residuals**2)\n",
    "        ss_tot = np.sum((y[valid]-np.mean(y[valid]))**2)\n",
    "        r_squared = 1 - (ss_res / ss_tot)\n",
    "        r2_values[i] = r_squared.round(2)\n",
    "        \n",
    "        #plot the regression line\n",
    "        axis[i//plt_columns, i%plt_columns].plot(x, func(x, *popt), 'r--')\n",
    "        axis[i//plt_columns, i%plt_columns].text(0.1, 0.8, f\"y={popt[0].round(2)}x\", transform=axis[i//plt_columns, i%plt_columns].transAxes)\n",
    "        axis[i//plt_columns, i%plt_columns].text(0.1, 0.7, f\"r2={r_squared.round(2)}\", transform=axis[i//plt_columns, i%plt_columns].transAxes)\n",
    "        axis[i//plt_columns, i%plt_columns].axis('square')\n",
    "    \n",
    "    #to remove the empty plots\n",
    "    for i in range(plt_columns*5-n_sensors):\n",
    "        axis[-1, -(i+1)].axis('off')\n",
    "\n",
    "    figure.set_size_inches(25, 16) #increase the plot's size\n",
    "    figure.subplots_adjust(hspace=0.05, wspace=0.075, top=0.96) #reduce the space between plots\n",
    "    \n",
    "    plt.suptitle(f\"{parameter} Harmonization\", fontsize=16)\n",
    "    plt.savefig(f'{result_folder}/{parameter}_harmonization_fitting.png', dpi=300)\n",
    "    #plt.show()\n",
    "\n",
    "    #\n",
    "    #plots\n",
    "    #plot the parameter vs time, truncating before 408\n",
    "    plt.figure(figsize=(16,9))\n",
    "    plt.plot(dates[:], median[:], label=\"median\")\n",
    "    for i in range(n_sensors):\n",
    "        plt.plot(dates[:], data[i][parameter].iloc[:], label=f\"sensor A{[i]}\")\n",
    "\n",
    "    #to save the harmonized data in a variable\n",
    "    for i in range(n_sensors):\n",
    "        harmonized_data[i][:] = data[i][parameter]*calibration_factors[i]\n",
    "\n",
    "    #cosmetics of the plot\n",
    "    plt.xlabel(\"Date\", fontsize=16)\n",
    "    plt.ylabel(parameter, fontsize=16)\n",
    "    plt.legend(loc=\"upper right\", fontsize=7)\n",
    "    plt.title(f\"{parameter} Harmonization\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{result_folder}/{parameter}_harmonization.png', dpi=300)\n",
    "    #plt.show()\n",
    "\n",
    "    return calibration_factors, harmonized_data, r2_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pm1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#get the data from harmonization\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m res_data \u001b[38;5;241m=\u001b[39m [harmonize(p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters]\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#get the data from harmonization\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m res_data \u001b[38;5;241m=\u001b[39m [\u001b[43mharmonize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters]\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mharmonize\u001b[0;34m(parameter)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mharmonize\u001b[39m(parameter):\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m#finding the median values for each timestamp - 'parameter_data' is 2-dimensional arrays to store the values of the parameter for all sensors\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     parameter_data \u001b[38;5;241m=\u001b[39m [data[i][parameter]\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_sensors)]\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m#cut off sensors with missing days to find the median in a simpler way\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     parameter_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([parameter_data[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_sensors)])\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mharmonize\u001b[39m(parameter):\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m#finding the median values for each timestamp - 'parameter_data' is 2-dimensional arrays to store the values of the parameter for all sensors\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     parameter_data \u001b[38;5;241m=\u001b[39m [\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mparameter\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_sensors)]\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m#cut off sensors with missing days to find the median in a simpler way\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     parameter_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([parameter_data[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_sensors)])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1069\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/range.py:389\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mget_loc(key, method\u001b[38;5;241m=\u001b[39mmethod, tolerance\u001b[38;5;241m=\u001b[39mtolerance)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'pm1'"
     ]
    }
   ],
   "source": [
    "#get the data from harmonization\n",
    "res_data = [harmonize(p) for p in parameters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get calibration factors and harmonized data\n",
    "calibration_factors = [res_data[i][0] for i, _ in enumerate(parameters)]\n",
    "r2_values = [res_data[i][2] for i, _ in enumerate(parameters)]\n",
    "harmonized_data = [res_data[i][1] for i, _ in enumerate(parameters)]\n",
    "\n",
    "#save the harmonized data in csv files, in level2_* folder\n",
    "for i in range(n_sensors):\n",
    "    sensor_harmonized_data = np.vstack([harmonized_data[j][i] for j, _ in enumerate(parameters)])\n",
    "    sensor_harmonized_dataframe = pd.DataFrame(sensor_harmonized_data.T, columns=parameters)\n",
    "    sensor_harmonized_dataframe.insert(0, time_header, dates)\n",
    "    sensor_harmonized_dataframe.to_csv(f'{result_folder}/{level2_folder}/{sensor_names[i]}.csv', index=False)\n",
    "\n",
    "#save the calibration factors in a csv file\n",
    "#TODO: add r2 values\n",
    "for i, parameter in enumerate(parameters):\n",
    "    if i == 0:\n",
    "        df_calibration_factors = pd.DataFrame(np.column_stack([calibration_factors[i], r2_values[i]]), columns=[f\"{parameter} CF\", f\"{parameter} R2\"])\n",
    "        df_calibration_factors.insert(0, \"sensor\", sensor_names)\n",
    "        df_calibration_factors.to_csv(f'{result_folder}/calibration_factors.csv', index=False)\n",
    "    else:\n",
    "        df_calibration_factors = pd.read_csv(f'{result_folder}/calibration_factors.csv')\n",
    "        df_calibration_factors[f\"{parameter} CF\"] = calibration_factors[i]\n",
    "        df_calibration_factors[f\"{parameter} R2\"] = r2_values[i]\n",
    "        df_calibration_factors.to_csv(f'{result_folder}/calibration_factors.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for PM2.5 HF:\n",
      "median is:0.99; mean is 1.0104761904761905\n",
      "min is:0.77; max is 1.33\n",
      "10the percentile is 0.85; 90the percentile is 1.14\n"
     ]
    }
   ],
   "source": [
    "#metadata of the calibration factors\n",
    "pm25_cf = calibration_factors[1]\n",
    "cf_median, cf_mean, cf_min, cf_max = np.nanmedian(pm25_cf), np.mean(pm25_cf), np.min(pm25_cf), np.max(pm25_cf)\n",
    "cf_10_perc, cf_90_perc = np.percentile(pm25_cf, 10), np.percentile(pm25_cf, 90)\n",
    "\n",
    "print(\"for PM2.5 HF:\")\n",
    "print(f\"median is:{cf_median}; mean is {cf_mean}\")\n",
    "print(f\"min is:{cf_min}; max is {cf_max}\")\n",
    "print(f\"10the percentile is {cf_10_perc}; 90the percentile is {cf_90_perc}\")\n",
    "#TODO\n",
    "#for the universal code\n",
    "#set protocol for the name of the csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
